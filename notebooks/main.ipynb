{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af43b9f",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33982418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5757795c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Корень проекта\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "\n",
    "sys.path.append(str(SRC_DIR))\n",
    "\n",
    "\n",
    "# Фиксация сидов для воспроизводимости\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# CUDA\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# MPS\n",
    "elif torch.backends.mps.is_available():\n",
    "    torch.mps.manual_seed(SEED)\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "\n",
    "\n",
    "# Определение девайса\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c3d6be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Id  Category\n",
      "0  trainval_00000.jpg         7\n",
      "1  trainval_00001.jpg       198\n",
      "2  trainval_00002.jpg       161\n",
      "3  trainval_00003.jpg       131\n",
      "4  trainval_00004.jpg       107\n",
      "Всего trainval: 100000\n",
      "Число классов: 200\n"
     ]
    }
   ],
   "source": [
    "# Пути к данным\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "\n",
    "TRAINVAL_DIR = DATA_DIR / \"trainval\"\n",
    "TEST_DIR = DATA_DIR / \"test\"\n",
    "LABELS_CSV = DATA_DIR / \"labels.csv\"\n",
    "\n",
    "assert TRAINVAL_DIR.exists()\n",
    "assert TEST_DIR.exists()\n",
    "assert LABELS_CSV.exists()\n",
    "\n",
    "# датасет с разметкой\n",
    "labels_df = pd.read_csv(LABELS_CSV)\n",
    "\n",
    "print(labels_df.head())\n",
    "print(\"Всего trainval:\", len(labels_df))\n",
    "print(\"Число классов:\", labels_df[\"Category\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c1128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 90000\n",
      "Val: 10000\n"
     ]
    }
   ],
   "source": [
    "# Разбиваем на train и val\n",
    "train_df, val_df = train_test_split(\n",
    "    labels_df,\n",
    "    test_size=0.1,\n",
    "    random_state=SEED,\n",
    "    stratify=labels_df[\"Category\"],\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(train_df))\n",
    "print(\"Val:\", len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "615342fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем датасеты\n",
    "from datasets.dataset import ImageClassificationDataset\n",
    "from datasets.transforms import get_base_transforms, get_train_transforms\n",
    "\n",
    "train_dataset = ImageClassificationDataset(\n",
    "    images_dir=TRAINVAL_DIR,\n",
    "    labels_df=train_df,\n",
    "    transform=get_train_transforms(),\n",
    ")\n",
    "\n",
    "val_dataset = ImageClassificationDataset(\n",
    "    images_dir=TRAINVAL_DIR,\n",
    "    labels_df=val_df,\n",
    "    transform=get_base_transforms(),\n",
    ")\n",
    "\n",
    "test_dataset = ImageClassificationDataset(\n",
    "    images_dir=TEST_DIR,\n",
    "    labels_df=None,\n",
    "    transform=get_base_transforms(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68c1d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем даталоадеры\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "PIN_MEMORY=True if device.type == \"cuda\" else False\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    persistent_workers = True,\n",
    "    prefetch_factor = 2,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    persistent_workers = True,\n",
    "    prefetch_factor = 2,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    persistent_workers = True,\n",
    "    prefetch_factor = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac7d055",
   "metadata": {},
   "source": [
    "## Модель и обучение\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9ed7799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем модель\n",
    "from models.simple_cnn import SimpleCNN\n",
    "from models.resnet18 import ResNet18\n",
    "from models.wide_resnet import WideResNet\n",
    "\n",
    "\n",
    "NUM_CLASSES = labels_df[\"Category\"].nunique()\n",
    "\n",
    "simple_cnn_model = SimpleCNN(num_classes=NUM_CLASSES).to(device)\n",
    "resnet18_model = ResNet18(num_classes=NUM_CLASSES).to(device)\n",
    "wide_resnet_model = WideResNet(num_classes=NUM_CLASSES, depth=10).to(device)\n",
    "\n",
    "# model = wide_resnet_model\n",
    "model = resnet18_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de8e90b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция потерь и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# optimizer = torch.optim.Adam(\n",
    "#     model.parameters(),\n",
    "#     lr=1e-3,\n",
    "# )\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.1,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=200  # 200 эпох\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27466c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.train import train_one_epoch\n",
    "from training.evaluate import evaluate\n",
    "import copy\n",
    "\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c70dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200] | LR: 0.099994 | Train loss: 5.1972, acc: 0.0159 | Val loss: 4.9508, acc: 0.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/200] | LR: 0.099975 | Train loss: 5.0033, acc: 0.0326 | Val loss: 4.7487, acc: 0.0605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200] | LR: 0.099944 | Train loss: 4.7530, acc: 0.0602 | Val loss: 4.4389, acc: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/200] | LR: 0.099901 | Train loss: 4.4852, acc: 0.0990 | Val loss: 4.1809, acc: 0.1449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200] | LR: 0.099846 | Train loss: 4.2873, acc: 0.1323 | Val loss: 3.9063, acc: 0.1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/200] | LR: 0.099778 | Train loss: 4.1308, acc: 0.1616 | Val loss: 3.7695, acc: 0.2262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  50%|█████     | 355/704 [01:07<01:06,  5.27it/s]"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model=model,\n",
    "        dataloader=train_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = evaluate(\n",
    "        model=model,\n",
    "        dataloader=val_loader,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch}/{EPOCHS}] | \"\n",
    "        f\"LR: {scheduler.get_last_lr()[0]:.6f} | \"\n",
    "        f\"Train loss: {train_loss:.4f}, acc: {train_acc:.4f} | \"\n",
    "        f\"Val loss: {val_loss:.4f}, acc: {val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    # сохраняем веса\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3d8cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db1b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_ids = []\n",
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, image_ids in tqdm(test_loader, desc=\"Inference\"):\n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        test_ids.extend(image_ids)\n",
    "        test_preds.extend(preds)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    \"Id\": test_ids,\n",
    "    \"Category\": test_preds,\n",
    "})\n",
    "\n",
    "submission_path = PROJECT_ROOT / \"outputs\" / \"labels_test.csv\"\n",
    "submission_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(\"Submission:\")\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
